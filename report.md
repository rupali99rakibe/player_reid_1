# ğŸ¥ Player Re-Identification â€“ Cross-Camera Mode

## ğŸ“Œ Objective
This mode aims to map player identities between two different camera views: **broadcast** and **tacticam**. It helps identify the same players captured from different camera angles.

---

## ğŸ“‚ Folder Structure

player_reid_1/
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ broadcast.mp4
â”‚ â””â”€â”€ tacticam.mp4
â”œâ”€â”€ models/
â”‚ â””â”€â”€ best.pt
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ common/
â”‚ â”‚ â”œâ”€â”€ detector.py
â”‚ â”‚ â”œâ”€â”€ tracker.py
â”‚ â”‚ â””â”€â”€ utils.py
â”‚ â””â”€â”€ cross_camera/
â”‚ â””â”€â”€ main.py
â”œâ”€â”€ output/
â”‚ â””â”€â”€ cross_camera_result.mp4


---

## âš™ï¸ Pipeline Overview

1. **Detection**: YOLOv8 model (`best.pt`) is used to detect players in both video feeds.
2. **Embedding Extraction**: Simple RGB average embedding is calculated per player crop.
3. **Re-identification**:
   - Compare each player in `tacticam.mp4` with players in `broadcast.mp4` (first frame).
   - Cosine similarity is used to determine identity match.
4. **Mapping Output**: The mapped identities are printed and optionally visualized.

---

## ğŸ“Š Result

| View         | Input              | Output Video              |
|--------------|--------------------|----------------------------|
| Cross-Camera | `broadcast.mp4`, `tacticam.mp4` | `cross_camera_result.mp4`|

---

## ğŸ§  Limitations
- Uses basic RGB embeddings.
- No spatial calibration between cameras.

---

## ğŸš€ Future Improvements
- Use deep embeddings from pre-trained ReID models.
- Add camera calibration or homography for better alignment.
- Improve matching with more temporal context.


